{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import transformers as T\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from collections import OrderedDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 27 19:43:32 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P8              11W /  70W |    105MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(imdb[\"train\"])\n",
    "df_test = pd.DataFrame(imdb[\"test\"])\n",
    "X = pd.DataFrame(df_train[\"text\"])\n",
    "y = df_train[\"label\"]\n",
    "X_test = pd.DataFrame(df_test[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initiate pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imker import Pipeline, Task, TaskConfig, BaseSplitter, BaseModel\n",
    "pipe = Pipeline(repo_dir=\"../../cache\", exp_name=\"imdb\", pipeline_name=\"example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter(BaseSplitter):\n",
    "    def __init__(self):\n",
    "        self.splitter = Task(TaskConfig(task=StratifiedKFold, \n",
    "                                    init_params={\"n_splits\":5, \"shuffle\":True}))\n",
    "\n",
    "    def get_n_splits(self):\n",
    "        return self.splitter.get_n_splits()\n",
    "    \n",
    "    def split(self, X, y=None):\n",
    "        return self.splitter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_splitter(Splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, \n",
    "                 tokenizer, \n",
    "                 truncation=True, \n",
    "                 cast_type=\"float\"):\n",
    "\n",
    "        self.truncation = truncation\n",
    "        self.cast_type = getattr(torch, cast_type)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def tokenize(self, X:str, y=None):\n",
    "\n",
    "        encode = self.tokenizer(\n",
    "                                X,\n",
    "                                truncation = self.truncation,\n",
    "                                return_attention_mask=True, \n",
    "                                return_tensors=\"pt\", \n",
    "                            )\n",
    "\n",
    "        if not y is None:\n",
    "            encode[\"labels\"] = torch.as_tensor(y).to(self.cast_type)\n",
    "        \n",
    "        encode = OrderedDict({k:v.squeeze() for k, v in encode.items()})\n",
    "\n",
    "        return encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 X:pd.DataFrame,  \n",
    "                 y:pd.Series,\n",
    "                 tokenizer\n",
    "                 ):\n",
    "\n",
    "        self.tokenizer = Tokenizer(tokenizer)\n",
    "        \n",
    "        self.data = X[\"text\"].to_numpy()\n",
    "        self.len_data = len(self.data)\n",
    "\n",
    "        self.labels = y.to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        inputs = self.data[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        encoded_inputs = {}\n",
    "        encoded = self.tokenizer.tokenize(inputs, label)\n",
    "        encoded_inputs.update(encoded)\n",
    "\n",
    "        return encoded_inputs\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 X:pd.DataFrame,  \n",
    "                 tokenizer\n",
    "                 ):\n",
    "\n",
    "        self.tokenizer = Tokenizer(tokenizer)\n",
    "        \n",
    "        self.data = X[\"text\"].to_numpy()\n",
    "        self.len_data = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        inputs = self.data[index]\n",
    "\n",
    "        encoded_inputs = {}\n",
    "        encoded = self.tokenizer.tokenize(inputs)\n",
    "        encoded_inputs.update(encoded)\n",
    "\n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imker.adapter.lightning import BaseLightningModule\n",
    "\n",
    "class TransformerModelForSequence(BaseLightningModule):\n",
    "    def __init__(self, \n",
    "                 model_name, \n",
    "                 num_labels, \n",
    "                 dropout_ratio=0.1, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.model = T.AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(dropout_ratio)\n",
    "        self.head = torch.nn.Linear(self.model.config.hidden_size, self.num_labels)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.model(input_ids=X[\"input_ids\"], \n",
    "                        attention_mask=X[\"attention_mask\"])\n",
    "        out = out[0][:, 0, :]\n",
    "        out = self.dropout(out)\n",
    "        out = self.head(out).squeeze()\n",
    "        return out\n",
    "\n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0):\n",
    "        out = self(batch)\n",
    "        return torch.where(torch.nn.functional.sigmoid(out)>=0.5, 1, 0)\n",
    "    \n",
    "    def compute_loss(self, batch):\n",
    "        y = batch.pop(\"labels\")\n",
    "        X = batch\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss(out, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imker.adapter.lightning import LightningTask\n",
    "\n",
    "class Classifier(BaseModel):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.transformer_model = \"distilbert-base-uncased\"\n",
    "        self.EPOCHS = 3\n",
    "        self.BATCH_SIZE = 16\n",
    "        self.N_ITERATIONS = self.EPOCHS * int(4/5 * 25000 // self.BATCH_SIZE) \n",
    "        tokenizer = T.AutoTokenizer.from_pretrained(self.transformer_model)\n",
    "        tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
    "\n",
    "        self.model = Task(TaskConfig(task=LightningTask, \n",
    "                                     init_params=dict(\n",
    "                                        model=TransformerModelForSequence, \n",
    "                                        train_dataset=TrainDataset, \n",
    "                                        valid_dataset=TrainDataset, \n",
    "                                        test_dataset=TestDataset, \n",
    "                                        model_init_params=dict(\n",
    "                                            model_name=self.transformer_model, \n",
    "                                            num_labels=1, \n",
    "                                            loss = torch.nn.BCEWithLogitsLoss, \n",
    "                                            optimizer=torch.optim.AdamW, \n",
    "                                            optimizer_params=dict(\n",
    "                                                lr=1e-5\n",
    "                                            ), \n",
    "                                            lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR, \n",
    "                                            lr_scheduler_params=dict(T_max=self.N_ITERATIONS)\n",
    "                                        ), \n",
    "                                        train_dataset_params=dict(\n",
    "                                            tokenizer = tokenizer, \n",
    "                                        ), \n",
    "                                        valid_dataset_params=dict(\n",
    "                                            tokenizer = tokenizer, \n",
    "                                        ), \n",
    "                                        test_dataset_params=dict(\n",
    "                                            tokenizer = tokenizer, \n",
    "                                        ), \n",
    "                                        epochs = self.EPOCHS, \n",
    "                                        batch_size = self.BATCH_SIZE, \n",
    "                                        early_stopping_round = 5, \n",
    "                                        collate_fn = DataCollatorWithPadding, \n",
    "                                        collate_fn_params = dict(tokenizer=tokenizer), \n",
    "                                        limit_train_batches = 0.1, # just for tutorial\n",
    "                                        loader_num_workers=0, \n",
    "                                        checkpoint_dir = \"../../checkpoint\", \n",
    "                                        logger=CSVLogger, \n",
    "                                        logger_params = dict(\n",
    "                                            save_dir=\"../../checkpoint\"\n",
    "                                        )\n",
    "                                    ), \n",
    "                                    cache=True)\n",
    "                        )\n",
    "\n",
    "    def forward(self, X, y=None, eval_set=None):\n",
    "        return {\"transformer\":self.model(X, y, eval_set=eval_set)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_model(Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold                :           split process takes 0.0000 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss    | BCEWithLogitsLoss | 0     \n",
      "1 | model   | DistilBertModel   | 66.4 M\n",
      "2 | dropout | Dropout           | 0     \n",
      "3 | head    | Linear            | 769   \n",
      "----------------------------------------------\n",
      "66.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.4 M    Total params\n",
      "265.455   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:17<00:00,  1.61it/s, v_num=0, train_loss_step=0.234, valid_loss_step=0.400] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:19<00:00,  1.56it/s, v_num=0, train_loss_step=0.234, valid_loss_step=0.400]\n",
      "LightningTask                  :             fit process takes 238.4449 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss    | BCEWithLogitsLoss | 0     \n",
      "1 | model   | DistilBertModel   | 66.4 M\n",
      "2 | dropout | Dropout           | 0     \n",
      "3 | head    | Linear            | 769   \n",
      "----------------------------------------------\n",
      "66.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.4 M    Total params\n",
      "265.455   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:17<00:00,  1.61it/s, v_num=1, train_loss_step=0.222, valid_loss_step=0.237] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:19<00:00,  1.56it/s, v_num=1, train_loss_step=0.222, valid_loss_step=0.237]\n",
      "LightningTask                  :             fit process takes 238.3958 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss    | BCEWithLogitsLoss | 0     \n",
      "1 | model   | DistilBertModel   | 66.4 M\n",
      "2 | dropout | Dropout           | 0     \n",
      "3 | head    | Linear            | 769   \n",
      "----------------------------------------------\n",
      "66.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.4 M    Total params\n",
      "265.455   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:17<00:00,  1.61it/s, v_num=2, train_loss_step=0.281, valid_loss_step=0.0713]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:19<00:00,  1.57it/s, v_num=2, train_loss_step=0.281, valid_loss_step=0.0713]\n",
      "LightningTask                  :             fit process takes 236.5010 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss    | BCEWithLogitsLoss | 0     \n",
      "1 | model   | DistilBertModel   | 66.4 M\n",
      "2 | dropout | Dropout           | 0     \n",
      "3 | head    | Linear            | 769   \n",
      "----------------------------------------------\n",
      "66.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.4 M    Total params\n",
      "265.455   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:16<00:00,  1.62it/s, v_num=3, train_loss_step=0.290, valid_loss_step=0.375] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:18<00:00,  1.58it/s, v_num=3, train_loss_step=0.290, valid_loss_step=0.375]\n",
      "LightningTask                  :             fit process takes 236.3300 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss    | BCEWithLogitsLoss | 0     \n",
      "1 | model   | DistilBertModel   | 66.4 M\n",
      "2 | dropout | Dropout           | 0     \n",
      "3 | head    | Linear            | 769   \n",
      "----------------------------------------------\n",
      "66.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.4 M    Total params\n",
      "265.455   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:17<00:00,  1.62it/s, v_num=4, train_loss_step=0.151, valid_loss_step=0.0371] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:19<00:00,  1.58it/s, v_num=4, train_loss_step=0.151, valid_loss_step=0.0371]\n",
      "LightningTask                  :             fit process takes 236.2818 [sec]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<imker.pipeline.pipeline.Pipeline at 0x7faaa6bfe220>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training config is automatically saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskId</th>\n",
       "      <th>lastUpdatedDate</th>\n",
       "      <th>repo</th>\n",
       "      <th>method</th>\n",
       "      <th>processor</th>\n",
       "      <th>cacheFile</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "      <td>2023-08-27T19:55:38.173250</td>\n",
       "      <td>../../cache</td>\n",
       "      <td>fit</td>\n",
       "      <td>LightningTask</td>\n",
       "      <td>../../cache/task/fit/LightningTask/c455b53e5e1...</td>\n",
       "      <td>../../cache/task/fit/LightningTask/c455b53e5e1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>2023-08-27T20:03:30.783287</td>\n",
       "      <td>../../cache</td>\n",
       "      <td>fit</td>\n",
       "      <td>LightningTask</td>\n",
       "      <td>../../cache/task/fit/LightningTask/68cfe8dfbee...</td>\n",
       "      <td>../../cache/task/fit/LightningTask/68cfe8dfbee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>2023-08-27T19:59:34.508272</td>\n",
       "      <td>../../cache</td>\n",
       "      <td>fit</td>\n",
       "      <td>LightningTask</td>\n",
       "      <td>../../cache/task/fit/LightningTask/5148be02c01...</td>\n",
       "      <td>../../cache/task/fit/LightningTask/5148be02c01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2023-08-27T19:51:41.662210</td>\n",
       "      <td>../../cache</td>\n",
       "      <td>fit</td>\n",
       "      <td>LightningTask</td>\n",
       "      <td>../../cache/task/fit/LightningTask/0e6864d835b...</td>\n",
       "      <td>../../cache/task/fit/LightningTask/0e6864d835b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18</td>\n",
       "      <td>2023-08-27T19:47:43.234984</td>\n",
       "      <td>../../cache</td>\n",
       "      <td>fit</td>\n",
       "      <td>LightningTask</td>\n",
       "      <td>../../cache/task/fit/LightningTask/0d12f5f221e...</td>\n",
       "      <td>../../cache/task/fit/LightningTask/0d12f5f221e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    taskId             lastUpdatedDate         repo method      processor  \\\n",
       "16      22  2023-08-27T19:55:38.173250  ../../cache    fit  LightningTask   \n",
       "17      21  2023-08-27T20:03:30.783287  ../../cache    fit  LightningTask   \n",
       "18      20  2023-08-27T19:59:34.508272  ../../cache    fit  LightningTask   \n",
       "19      19  2023-08-27T19:51:41.662210  ../../cache    fit  LightningTask   \n",
       "20      18  2023-08-27T19:47:43.234984  ../../cache    fit  LightningTask   \n",
       "\n",
       "                                            cacheFile  \\\n",
       "16  ../../cache/task/fit/LightningTask/c455b53e5e1...   \n",
       "17  ../../cache/task/fit/LightningTask/68cfe8dfbee...   \n",
       "18  ../../cache/task/fit/LightningTask/5148be02c01...   \n",
       "19  ../../cache/task/fit/LightningTask/0e6864d835b...   \n",
       "20  ../../cache/task/fit/LightningTask/0d12f5f221e...   \n",
       "\n",
       "                                               config  \n",
       "16  ../../cache/task/fit/LightningTask/c455b53e5e1...  \n",
       "17  ../../cache/task/fit/LightningTask/68cfe8dfbee...  \n",
       "18  ../../cache/task/fit/LightningTask/5148be02c01...  \n",
       "19  ../../cache/task/fit/LightningTask/0e6864d835b...  \n",
       "20  ../../cache/task/fit/LightningTask/0d12f5f221e...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imker import RepositoryViewer\n",
    "viewer = RepositoryViewer(repo_dir=\"../../cache/\")\n",
    "viewer.search_repo().pipe(lambda x:x[x[\"processor\"]==\"LightningTask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_params': {'batch_size': 16,\n",
       "  'checkpoint_dir': '../../checkpoint',\n",
       "  'collate_fn': 'DataCollatorWithPadding',\n",
       "  'collate_fn_params': {'tokenizer': 'DistilBertTokenizerFast'},\n",
       "  'early_stopping_round': 5,\n",
       "  'epochs': 3,\n",
       "  'limit_train_batches': 0.1,\n",
       "  'loader_num_workers': 0,\n",
       "  'logger': 'CSVLogger',\n",
       "  'logger_params': {'save_dir': '../../checkpoint'},\n",
       "  'model': 'TransformerModelForSequence',\n",
       "  'model_init_params': {'loss': 'BCEWithLogitsLoss',\n",
       "   'lr_scheduler': 'CosineAnnealingLR',\n",
       "   'lr_scheduler_params': {'T_max': 3750},\n",
       "   'model_name': 'distilbert-base-uncased',\n",
       "   'num_labels': 1,\n",
       "   'optimizer': 'AdamW',\n",
       "   'optimizer_params': {'lr': 1e-05}},\n",
       "  'test_dataset': 'TestDataset',\n",
       "  'test_dataset_params': {'tokenizer': 'DistilBertTokenizerFast'},\n",
       "  'train_dataset': 'TrainDataset',\n",
       "  'train_dataset_params': {'tokenizer': 'DistilBertTokenizerFast'},\n",
       "  'valid_dataset': 'TrainDataset',\n",
       "  'valid_dataset_params': {'tokenizer': 'DistilBertTokenizerFast'}},\n",
       " 'fit_params': {},\n",
       " 'transform_params': {},\n",
       " 'predict_params': {},\n",
       " 'cache_processor': 'PickledBz2Cacher',\n",
       " 'seed': 42}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.load_config(task_id=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "pipe.set_metrics([accuracy_score, f1_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold                :           split process takes 0.0000 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:34<00:00,  3.32it/s]\n",
      "LightningTask                  :         forward process takes 95.7584 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:33<00:00,  3.35it/s]\n",
      "LightningTask                  :         forward process takes 95.1411 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:33<00:00,  3.36it/s]\n",
      "LightningTask                  :         forward process takes 94.7321 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:32<00:00,  3.37it/s]\n",
      "LightningTask                  :         forward process takes 94.4435 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:33<00:00,  3.35it/s]\n",
      "LightningTask                  :         forward process takes 94.9493 [sec]\n"
     ]
    }
   ],
   "source": [
    "val_preds = pipe.validate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fold0</th>\n",
       "      <th>fold1</th>\n",
       "      <th>fold2</th>\n",
       "      <th>fold3</th>\n",
       "      <th>fold4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">transformer</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.905200</td>\n",
       "      <td>0.911400</td>\n",
       "      <td>0.904800</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.903107</td>\n",
       "      <td>0.910523</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.894026</td>\n",
       "      <td>0.899249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fold0     fold1     fold2     fold3     fold4\n",
       "transformer accuracy_score  0.905200  0.911400  0.904800  0.896400  0.895400\n",
       "            f1_score        0.903107  0.910523  0.905405  0.894026  0.899249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the prediction results for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds.transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the prediction results was cached, so you can access it again without taking time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold                :           split process takes 0.0000 [sec]\n",
      "LightningTask                  :         forward process takes 0.0963 [sec]\n",
      "LightningTask                  :         forward process takes 0.0715 [sec]\n",
      "LightningTask                  :         forward process takes 0.0715 [sec]\n",
      "LightningTask                  :         forward process takes 0.0737 [sec]\n",
      "LightningTask                  :         forward process takes 0.0713 [sec]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataContainer([('transformer', array([0, 0, 0, ..., 1, 1, 1]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.validate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference takes a little long time with T4 GPU, so I omit it this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds = pipe.inference(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline.load(\n",
    "    repo_dir=\"../../cache\", \n",
    "    exp_name=\"imdb\", \n",
    "    pipeline_name=\"example\", \n",
    "    splitter = Splitter, \n",
    "    model = Classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold                :           split process takes 0.0000 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:33<00:00,  3.34it/s]\n",
      "LightningTask                  :         forward process takes 95.0915 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:33<00:00,  3.36it/s]\n",
      "LightningTask                  :         forward process takes 94.5513 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:33<00:00,  3.36it/s]\n",
      "LightningTask                  :         forward process takes 94.7389 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:32<00:00,  3.37it/s]\n",
      "LightningTask                  :         forward process takes 94.3974 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [01:33<00:00,  3.36it/s]\n",
      "LightningTask                  :         forward process takes 94.6299 [sec]\n"
     ]
    }
   ],
   "source": [
    "val_preds2 = pipe2.validate(X, y, calc_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(val_preds.transformer==val_preds2.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "500ef7af0a45a2a87ce4de1b05b1a29367fbdc20ae7e8d43fffb37bcd2c9a6a1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.17 ('imker-dev-KpqCCnLP-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
